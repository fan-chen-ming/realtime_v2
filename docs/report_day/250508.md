> Author: chenming
> Date:   2025-05-08
> Desc :

>  job name : 实时数仓


1.项目背景：
互联网技术的发展，电子商务行业蓬勃发展，尤其是移动购物的兴起，使得电商平台每天都会产生海量的数据，包括但不限于用户的浏览记录、点击流、交易记录等。这些数据蕴含着巨大的商业价值，但同时也给数据分析带来了挑战：如何在短时间内处理和分析这些数据，并从中提取出有用的信息成为了一个重要的课题。

传统的离线数据处理方式已经无法满足现代电商平台对于数据处理速度的需求，因此，实时数据仓库应运而生。它能够在数据产生的同时对其进行处理，大幅缩短了数据从生成到可用的时间差，使得企业可以基于最新的数据做出更迅速、准确的决策。



2.架构流程：
![[Pasted image 20250508082748.png]]
我们的目标是构建一个高效、实时且可扩展的数据处理平台，用于支持业务决策和数据分析。接下来，我将从数据的采集、处理、存储到最终的可视化展示，分步骤地介绍整个系统的架构设计。

首先，让我们从数据的源头开始。在Web/App业务交互层，用户的行为数据通过Nginx服务器被收集。这些数据一方面直接进入业务服务器（基于Springboot框架），另一方面则通过前端埋点技术，记录用户的操作行为，并发送至日志服务器。这样的设计确保了数据的全面性和准确性，为后续的分析提供了坚实的基础。

接着，我们关注数据的传输与初步处理阶段。业务服务器处理后的数据会被实时同步至MySQL数据库，同时，日志文件通过Flume工具被采集并送入Kafka消息队列中。这里，Maxwell工具起到了关键的作用，它能够实时捕获MySQL数据库中的变更数据，并将其转化为事件流，进一步增强了数据的实时性。而Kafka作为消息中间件，不仅保证了数据传输的可靠性，还为后续的大规模并行处理提供了可能。

然后，我们来到了数据处理的核心——Flink流处理引擎。在dwd层，Flink对来自Kafka的消息进行清洗、广播join等操作，筛选出维度表，为后续的分析做准备。在dim层，Flink继续发挥其强大的计算能力，对数据进行关联维度的旁路缓存和异步IO处理，确保数据的一致性和完整性。而在dws层，Flink实现了多流合并、维度关联、状态去重等功能，精确一次性消费，保证了数据处理的准确性和效率。最后，在dwd层，Flink对事实数据进行关联、维度退化和独立访客统计，生成宽表，为上层应用提供丰富的数据支持。

在数据存储方面，我们采用了多种存储方案以满足不同的需求。维度数据被存储在HBase中，利用其高并发读写和大容量存储的特点；而宽表则被存储在Doris中，以便于快速查询和分析。此外，Redis作为旁路缓存，提高了数据访问的速度，优化了系统的整体性能。


3.技术栈广
![[Pasted image 20250508083003.png]]


4.项目内容

1. **数据采集**：通过Flume等工具采集来自Web服务器、应用服务器的日志文件以及业务数据库中的变更数据。

2. **数据传输**：使用Kafka作为消息队列中间件，实现高效、可靠的数据传输，确保数据在各个组件之间的流转。

3. **数据处理**：
    - 利用Flink进行实时数据处理，包括数据清洗、转换、聚合等操作。
    - 在不同的数据层（如ODS原始数据层、DWD明细数据层、DWS服务数据层、ADS应用数据层）中进行相应的数据处理，为上层应用提供干净、易用的数据支持。
    -
4. **数据存储与查询**：将处理后的数据存储在适合的数据库中，比如HBase用于存储大规模的非结构化数据，Redis用于缓存热点数据，Doris用于快速查询分析宽表等。

5. **数据可视化**：通过Sugar等BI工具对接处理后的数据，为企业提供直观的数据展示和分析能力，帮助企业管理层更好地理解市场动态和用户需求。



5.项目成果

- **性能指标**：

    - 数据端到端延迟：<3秒（从MySQL更新到Doris可查询）。

    - 查询响应：95%的OLAP请求<1秒。

- **业务价值**：

    - 实时大屏：支持运营实时监控GMV、UV等核心指标。

    - 精准营销：基于实时用户行为触发优惠券发放，转化率提升15%。


